{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ensemble with Detectron2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaeminSon/Google_Code_Jam/blob/master/Ensemble_with_Detectron2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPDhYYTrLEc4",
        "outputId": "3691796f-8fad-446e-a3f6-a17eb96c7f20"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8VLyD9Juu7w"
      },
      "source": [
        "# !wget http://images.cocodataset.org/zips/train2017.zip\n",
        "!wget http://images.cocodataset.org/zips/val2017.zip\n",
        "# !wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
        "# !unzip train2017.zip\n",
        "!unzip val2017.zip\n",
        "# !unzip annotations_trainval2017.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRg7VOnp5zLX"
      },
      "source": [
        "# remove truncated image & zip file in training set\n",
        "!rm train2017.zip\n",
        "!rm train2017/000000081166.jpg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_FzH13EjseR"
      },
      "source": [
        "# # install detectron2: (Colab has CUDA 10.1 + torch 1.7)\n",
        "!pip install pyyaml==5.1\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.7/index.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyAvNCJMmvFF"
      },
      "source": [
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import torch\n",
        "assert torch.__version__.startswith(\"1.7\")\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "from detectron2.data.datasets import register_coco_instances"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_q863ZrnNaD",
        "outputId": "5d2c5a3e-7038-4317-8412-49fa1f82db06"
      },
      "source": [
        "import json\n",
        "import random\n",
        "import os\n",
        "\n",
        "# # sample training dataset for inference (compute time limit)\n",
        "# path_sampled_json = \"annotations/sampled_instance_train2017.json\"\n",
        "# if not os.path.exists(path_sampled_json):\n",
        "#   with open(\"./annotations/instances_train2017.json\") as f:\n",
        "#     label = json.load(f)\n",
        "#   new_labels = {\"annotations\":[], \"images\":[]}\n",
        "#   for key in ['info', 'licenses', 'categories', 'annotations']:\n",
        "#     new_labels[key] = label[key]\n",
        "#   imgs = os.listdir(\"train2017\")\n",
        "#   selected_imgs = set(random.sample(imgs, len(imgs)//20))\n",
        "#   for label_img in label[\"images\"]:\n",
        "#     if label_img[\"file_name\"] in selected_imgs:\n",
        "#       new_labels[\"images\"].append(label_img)\n",
        "\n",
        "#   with open(path_sampled_json, \"w\") as f:\n",
        "#     json.dump(new_labels, f)\n",
        "\n",
        "# # register dataset\n",
        "# register_coco_instances(\"train2017\", {}, path_sampled_json, \"./train2017\")\n",
        "# dicts_train2017 = DatasetCatalog.get(\"train2017\")\n",
        "# metadata_train2017 = MetadataCatalog.get(\"train2017\")\n",
        "register_coco_instances(\"val2017\", {}, \"./annotations/instances_val2017.json\", \"./val2017\")\n",
        "dicts_val2017 = DatasetCatalog.get(\"val2017\")\n",
        "metadata_val2017 = MetadataCatalog.get(\"val2017\")"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/24 11:42:51 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[01/24 11:42:51 d2.data.datasets.coco]: \u001b[0mLoaded 5000 images in COCO format from ./annotations/instances_val2017.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUjkwRsOn1O0"
      },
      "source": [
        "dict_cfg = {}\n",
        "# faster rcnn X101-FPN\n",
        "dict_cfg[\"x101\"] = get_cfg()\n",
        "dict_cfg[\"x101\"].merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n",
        "dict_cfg[\"x101\"].MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\")\n",
        "dict_cfg[\"x101\"].DATASETS.TEST = (\"val2017\", )\n",
        "# faster rcnn R101-FPN\n",
        "dict_cfg[\"r101_fpn\"] = get_cfg()\n",
        "dict_cfg[\"r101_fpn\"].merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\"))\n",
        "dict_cfg[\"r101_fpn\"].MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\")\n",
        "dict_cfg[\"r101_fpn\"].DATASETS.TEST = (\"val2017\", )\n",
        "# RPN & Fast R101-C4\n",
        "dict_cfg[\"r101_c4\"] = get_cfg()\n",
        "dict_cfg[\"r101_c4\"].merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_101_C4_3x.yaml\"))\n",
        "dict_cfg[\"r101_c4\"].MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_101_C4_3x.yaml\")\n",
        "dict_cfg[\"r101_c4\"].DATASETS.TEST = (\"val2017\", )\n",
        "os.makedirs(dict_cfg[\"x101\"].OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "dict_models = {}\n",
        "dict_models[\"x101\"] = DefaultPredictor(dict_cfg[\"x101\"]).model\n",
        "dict_models[\"r101_fpn\"] = DefaultPredictor(dict_cfg[\"r101_fpn\"]).model\n",
        "dict_models[\"r101_c4\"] = DefaultPredictor(dict_cfg[\"r101_c4\"]).model\n"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oy11Xlls82HR"
      },
      "source": [
        "# run inference models\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "\n",
        "# for dataset in [\"train2017\", \"val2017\"]:\n",
        "# for dataset in [\"val2017\"]:\n",
        "for dataset in [\"train2017\"]:\n",
        "  for model_name, model in dict_models.items():\n",
        "    print(model_name)\n",
        "    evaluator = COCOEvaluator(dataset, dict_cfg[model_name], False, output_dir=\"./{}_{}_outputs/\".format(dataset, model_name))\n",
        "    val_loader = build_detection_test_loader(dict_cfg[model_name], dataset)\n",
        "    print(inference_on_dataset(model, val_loader, evaluator))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVrJS31EL7OC"
      },
      "source": [
        "# !cp -r val2017_x101_outputs gdrive/MyDrive\n",
        "# !cp -r val2017_r101_fpn_outputs gdrive/MyDrive\n",
        "# !cp -r val2017_r101_c4_outputs gdrive/MyDrive\n",
        "!cp -r train2017_x101_outputs gdrive/MyDrive\n",
        "!cp -r train2017_r101_fpn_outputs gdrive/MyDrive\n",
        "!cp -r train2017_r101_c4_outputs gdrive/MyDrive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8X-C8_N2UF4M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7dcc327-7f0d-492b-8495-e0a1b47e864f"
      },
      "source": [
        "# measure individual model's performance\n",
        "for dataset in [\"val2017\"]:\n",
        "  for model_name, model in dict_models.items():\n",
        "    evaluator = COCOEvaluator(dataset, dict_cfg[model_name], False)\n",
        "    predictions = torch.load(\"./gdrive/MyDrive/{}_{}_outputs/instances_predictions.pth\".format(dataset, model_name))\n",
        "    evaluator._predictions = predictions\n",
        "    evaluator.evaluate()"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/24 11:42:58 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly\n",
            "\u001b[32m[01/24 11:43:03 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[01/24 11:43:03 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.14s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "COCOeval_opt.evaluate() finished in 7.92 seconds.\n",
            "Accumulating evaluation results...\n",
            "COCOeval_opt.accumulate() finished in 0.88 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.430\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.637\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.469\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.272\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.461\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.549\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.341\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.530\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.553\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.373\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.580\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.689\n",
            "\u001b[32m[01/24 11:43:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 43.047 | 63.652 | 46.888 | 27.205 | 46.093 | 54.890 |\n",
            "\u001b[32m[01/24 11:43:12 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category     | AP     | category       | AP     |\n",
            "|:--------------|:-------|:-------------|:-------|:---------------|:-------|\n",
            "| person        | 56.584 | bicycle      | 33.478 | car            | 46.274 |\n",
            "| motorcycle    | 44.864 | airplane     | 65.970 | bus            | 67.801 |\n",
            "| train         | 63.855 | truck        | 37.523 | boat           | 29.088 |\n",
            "| traffic light | 28.431 | fire hydrant | 67.848 | stop sign      | 67.426 |\n",
            "| parking meter | 47.115 | bench        | 26.732 | bird           | 40.608 |\n",
            "| cat           | 68.564 | dog          | 63.084 | horse          | 60.519 |\n",
            "| sheep         | 52.939 | cow          | 57.419 | elephant       | 62.942 |\n",
            "| bear          | 71.289 | zebra        | 66.869 | giraffe        | 66.830 |\n",
            "| backpack      | 18.215 | umbrella     | 40.402 | handbag        | 16.905 |\n",
            "| tie           | 36.589 | suitcase     | 43.065 | frisbee        | 67.470 |\n",
            "| skis          | 26.227 | snowboard    | 38.807 | sports ball    | 48.196 |\n",
            "| kite          | 42.842 | baseball bat | 31.106 | baseball glove | 40.043 |\n",
            "| skateboard    | 56.111 | surfboard    | 40.490 | tennis racket  | 51.013 |\n",
            "| bottle        | 40.653 | wine glass   | 38.639 | cup            | 44.779 |\n",
            "| fork          | 40.702 | knife        | 22.446 | spoon          | 21.464 |\n",
            "| bowl          | 42.973 | banana       | 23.170 | apple          | 24.199 |\n",
            "| sandwich      | 33.904 | orange       | 31.624 | broccoli       | 22.489 |\n",
            "| carrot        | 21.827 | hot dog      | 34.902 | pizza          | 52.478 |\n",
            "| donut         | 45.543 | cake         | 36.834 | chair          | 29.421 |\n",
            "| couch         | 43.671 | potted plant | 28.094 | bed            | 41.796 |\n",
            "| dining table  | 28.766 | toilet       | 60.039 | tv             | 58.110 |\n",
            "| laptop        | 61.864 | mouse        | 62.764 | remote         | 34.984 |\n",
            "| keyboard      | 52.624 | cell phone   | 38.827 | microwave      | 61.060 |\n",
            "| oven          | 33.099 | toaster      | 36.892 | sink           | 37.416 |\n",
            "| refrigerator  | 55.290 | book         | 15.653 | clock          | 50.330 |\n",
            "| vase          | 37.752 | scissors     | 27.406 | teddy bear     | 46.587 |\n",
            "| hair drier    | 5.592  | toothbrush   | 25.559 |                |        |\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/24 11:43:12 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly\n",
            "\u001b[32m[01/24 11:43:13 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[01/24 11:43:14 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.18s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "COCOeval_opt.evaluate() finished in 8.36 seconds.\n",
            "Accumulating evaluation results...\n",
            "COCOeval_opt.accumulate() finished in 0.95 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.420\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.625\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.459\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.252\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.456\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.546\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.339\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.530\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.555\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.364\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.589\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.700\n",
            "\u001b[32m[01/24 11:43:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 42.036 | 62.480 | 45.876 | 25.225 | 45.554 | 54.592 |\n",
            "\u001b[32m[01/24 11:43:23 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category     | AP     | category       | AP     |\n",
            "|:--------------|:-------|:-------------|:-------|:---------------|:-------|\n",
            "| person        | 55.670 | bicycle      | 32.057 | car            | 45.341 |\n",
            "| motorcycle    | 44.380 | airplane     | 64.634 | bus            | 64.546 |\n",
            "| train         | 61.382 | truck        | 36.050 | boat           | 29.240 |\n",
            "| traffic light | 28.499 | fire hydrant | 68.264 | stop sign      | 65.690 |\n",
            "| parking meter | 48.340 | bench        | 24.528 | bird           | 35.775 |\n",
            "| cat           | 67.965 | dog          | 59.220 | horse          | 57.978 |\n",
            "| sheep         | 52.739 | cow          | 56.256 | elephant       | 62.249 |\n",
            "| bear          | 70.962 | zebra        | 66.295 | giraffe        | 67.768 |\n",
            "| backpack      | 16.479 | umbrella     | 38.766 | handbag        | 16.336 |\n",
            "| tie           | 36.839 | suitcase     | 41.267 | frisbee        | 62.656 |\n",
            "| skis          | 25.638 | snowboard    | 35.794 | sports ball    | 47.209 |\n",
            "| kite          | 43.456 | baseball bat | 28.818 | baseball glove | 37.902 |\n",
            "| skateboard    | 51.981 | surfboard    | 40.177 | tennis racket  | 50.079 |\n",
            "| bottle        | 40.178 | wine glass   | 37.022 | cup            | 44.357 |\n",
            "| fork          | 38.863 | knife        | 20.129 | spoon          | 19.123 |\n",
            "| bowl          | 42.849 | banana       | 23.185 | apple          | 22.197 |\n",
            "| sandwich      | 34.158 | orange       | 32.679 | broccoli       | 24.061 |\n",
            "| carrot        | 23.870 | hot dog      | 33.645 | pizza          | 52.537 |\n",
            "| donut         | 47.135 | cake         | 36.963 | chair          | 28.276 |\n",
            "| couch         | 42.790 | potted plant | 26.102 | bed            | 39.368 |\n",
            "| dining table  | 29.136 | toilet       | 59.627 | tv             | 57.222 |\n",
            "| laptop        | 60.667 | mouse        | 63.490 | remote         | 32.923 |\n",
            "| keyboard      | 51.298 | cell phone   | 35.199 | microwave      | 55.622 |\n",
            "| oven          | 32.937 | toaster      | 35.872 | sink           | 38.200 |\n",
            "| refrigerator  | 55.022 | book         | 15.472 | clock          | 49.987 |\n",
            "| vase          | 37.283 | scissors     | 28.392 | teddy bear     | 46.032 |\n",
            "| hair drier    | 2.872  | toothbrush   | 26.902 |                |        |\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/24 11:43:24 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly\n",
            "\u001b[32m[01/24 11:43:25 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[01/24 11:43:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.23s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "COCOeval_opt.evaluate() finished in 8.90 seconds.\n",
            "Accumulating evaluation results...\n",
            "COCOeval_opt.accumulate() finished in 1.06 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.411\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.614\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.441\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.222\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.455\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.559\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.340\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.527\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.550\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.335\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.599\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.721\n",
            "\u001b[32m[01/24 11:43:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 41.069 | 61.407 | 44.059 | 22.191 | 45.462 | 55.867 |\n",
            "\u001b[32m[01/24 11:43:35 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category     | AP     | category       | AP     |\n",
            "|:--------------|:-------|:-------------|:-------|:---------------|:-------|\n",
            "| person        | 54.049 | bicycle      | 33.419 | car            | 41.471 |\n",
            "| motorcycle    | 44.671 | airplane     | 65.596 | bus            | 66.531 |\n",
            "| train         | 64.766 | truck        | 34.992 | boat           | 27.253 |\n",
            "| traffic light | 24.343 | fire hydrant | 68.571 | stop sign      | 64.437 |\n",
            "| parking meter | 45.912 | bench        | 25.266 | bird           | 34.649 |\n",
            "| cat           | 68.804 | dog          | 61.249 | horse          | 57.700 |\n",
            "| sheep         | 50.311 | cow          | 54.073 | elephant       | 61.327 |\n",
            "| bear          | 69.562 | zebra        | 68.025 | giraffe        | 66.773 |\n",
            "| backpack      | 15.611 | umbrella     | 39.713 | handbag        | 14.106 |\n",
            "| tie           | 32.820 | suitcase     | 37.592 | frisbee        | 59.976 |\n",
            "| skis          | 24.468 | snowboard    | 37.592 | sports ball    | 39.968 |\n",
            "| kite          | 40.006 | baseball bat | 25.198 | baseball glove | 34.654 |\n",
            "| skateboard    | 52.640 | surfboard    | 37.470 | tennis racket  | 49.835 |\n",
            "| bottle        | 35.977 | wine glass   | 35.174 | cup            | 40.657 |\n",
            "| fork          | 36.453 | knife        | 17.767 | spoon          | 18.774 |\n",
            "| bowl          | 40.694 | banana       | 22.810 | apple          | 19.272 |\n",
            "| sandwich      | 31.920 | orange       | 29.773 | broccoli       | 23.873 |\n",
            "| carrot        | 22.934 | hot dog      | 30.334 | pizza          | 52.485 |\n",
            "| donut         | 46.335 | cake         | 33.516 | chair          | 26.995 |\n",
            "| couch         | 42.150 | potted plant | 28.607 | bed            | 39.936 |\n",
            "| dining table  | 29.556 | toilet       | 60.719 | tv             | 57.374 |\n",
            "| laptop        | 62.541 | mouse        | 58.075 | remote         | 27.774 |\n",
            "| keyboard      | 51.455 | cell phone   | 32.710 | microwave      | 54.430 |\n",
            "| oven          | 35.070 | toaster      | 47.968 | sink           | 36.436 |\n",
            "| refrigerator  | 58.016 | book         | 13.024 | clock          | 47.613 |\n",
            "| vase          | 35.240 | scissors     | 26.282 | teddy bear     | 46.315 |\n",
            "| hair drier    | 10.895 | toothbrush   | 22.203 |                |        |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7GTD-923UbS"
      },
      "source": [
        "dataset = \"val2017\"\n",
        "dict_predictions = {}\n",
        "for model_name in dict_models.keys():\n",
        "  dict_predictions[model_name] = torch.load(\"./gdrive/MyDrive/{}_{}_outputs/instances_predictions.pth\".format(dataset, model_name))\n",
        "  dict_predictions[model_name] = sorted(dict_predictions[model_name], key=lambda x:x[\"image_id\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyGyIisEZKYk"
      },
      "source": [
        "# weighted box fusion code from https://github.com/ZFTurbo/Weighted-Boxes-Fusion\n",
        "import warnings\n",
        "import numpy as np\n",
        "from numba import jit\n",
        "\n",
        "\n",
        "@jit(nopython=True)\n",
        "def bb_intersection_over_union(A, B) -> float:\n",
        "    xA = max(A[0], B[0])\n",
        "    yA = max(A[1], B[1])\n",
        "    xB = min(A[2], B[2])\n",
        "    yB = min(A[3], B[3])\n",
        "\n",
        "    # compute the area of intersection rectangle\n",
        "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
        "\n",
        "    if interArea == 0:\n",
        "        return 0.0\n",
        "\n",
        "    # compute the area of both the prediction and ground-truth rectangles\n",
        "    boxAArea = (A[2] - A[0]) * (A[3] - A[1])\n",
        "    boxBArea = (B[2] - B[0]) * (B[3] - B[1])\n",
        "\n",
        "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
        "    return iou\n",
        "\n",
        "\n",
        "def prefilter_boxes(boxes, scores, labels, weights, thr):\n",
        "    # Create dict with boxes stored by its label\n",
        "    new_boxes = dict()\n",
        "\n",
        "    for t in range(len(boxes)):\n",
        "\n",
        "        if len(boxes[t]) != len(scores[t]):\n",
        "            print('Error. Length of boxes arrays not equal to length of scores array: {} != {}'.format(len(boxes[t]), len(scores[t])))\n",
        "            exit()\n",
        "\n",
        "        if len(boxes[t]) != len(labels[t]):\n",
        "            print('Error. Length of boxes arrays not equal to length of labels array: {} != {}'.format(len(boxes[t]), len(labels[t])))\n",
        "            exit()\n",
        "\n",
        "        for j in range(len(boxes[t])):\n",
        "            score = scores[t][j]\n",
        "            if score < thr:\n",
        "                continue\n",
        "            label = int(labels[t][j])\n",
        "            box_part = boxes[t][j]\n",
        "            x1 = float(box_part[0])\n",
        "            y1 = float(box_part[1])\n",
        "            x2 = float(box_part[2])\n",
        "            y2 = float(box_part[3])\n",
        "\n",
        "            # Box data checks\n",
        "            if x2 < x1:\n",
        "                warnings.warn('X2 < X1 value in box. Swap them.')\n",
        "                x1, x2 = x2, x1\n",
        "            if y2 < y1:\n",
        "                warnings.warn('Y2 < Y1 value in box. Swap them.')\n",
        "                y1, y2 = y2, y1\n",
        "            if x1 < 0:\n",
        "                warnings.warn('X1 < 0 in box. Set it to 0.')\n",
        "                x1 = 0\n",
        "            if x1 > 1:\n",
        "                warnings.warn('X1 > 1 in box. Set it to 1. Check that you normalize boxes in [0, 1] range.')\n",
        "                x1 = 1\n",
        "            if x2 < 0:\n",
        "                warnings.warn('X2 < 0 in box. Set it to 0.')\n",
        "                x2 = 0\n",
        "            if x2 > 1:\n",
        "                warnings.warn('X2 > 1 in box. Set it to 1. Check that you normalize boxes in [0, 1] range.')\n",
        "                x2 = 1\n",
        "            if y1 < 0:\n",
        "                warnings.warn('Y1 < 0 in box. Set it to 0.')\n",
        "                y1 = 0\n",
        "            if y1 > 1:\n",
        "                warnings.warn('Y1 > 1 in box. Set it to 1. Check that you normalize boxes in [0, 1] range.')\n",
        "                y1 = 1\n",
        "            if y2 < 0:\n",
        "                warnings.warn('Y2 < 0 in box. Set it to 0.')\n",
        "                y2 = 0\n",
        "            if y2 > 1:\n",
        "                warnings.warn('Y2 > 1 in box. Set it to 1. Check that you normalize boxes in [0, 1] range.')\n",
        "                y2 = 1\n",
        "            if (x2 - x1) * (y2 - y1) == 0.0:\n",
        "                warnings.warn(\"Zero area box skipped: {}.\".format(box_part))\n",
        "                continue\n",
        "\n",
        "            b = [int(label), float(score) * weights[t], x1, y1, x2, y2]\n",
        "            if label not in new_boxes:\n",
        "                new_boxes[label] = []\n",
        "            new_boxes[label].append(b)\n",
        "\n",
        "    # Sort each list in dict by score and transform it to numpy array\n",
        "    for k in new_boxes:\n",
        "        current_boxes = np.array(new_boxes[k])\n",
        "        new_boxes[k] = current_boxes[current_boxes[:, 1].argsort()[::-1]]\n",
        "\n",
        "    return new_boxes\n",
        "\n",
        "\n",
        "def get_weighted_box(boxes, conf_type='avg'):\n",
        "    \"\"\"\n",
        "    Create weighted box for set of boxes\n",
        "    :param boxes: set of boxes to fuse\n",
        "    :param conf_type: type of confidence one of 'avg' or 'max'\n",
        "    :return: weighted box\n",
        "    \"\"\"\n",
        "\n",
        "    box = np.zeros(6, dtype=np.float32)\n",
        "    conf = 0\n",
        "    conf_list = []\n",
        "    for b in boxes:\n",
        "        box[2:] += (b[1] * b[2:])\n",
        "        conf += b[1]\n",
        "        conf_list.append(b[1])\n",
        "    box[0] = boxes[0][0]\n",
        "    if conf_type == 'avg':\n",
        "        box[1] = conf / len(boxes)\n",
        "    elif conf_type == 'max':\n",
        "        box[1] = np.array(conf_list).max()\n",
        "    box[2:] /= conf\n",
        "    return box\n",
        "\n",
        "\n",
        "def find_matching_box(boxes_list, new_box, match_iou):\n",
        "    best_iou = match_iou\n",
        "    best_index = -1\n",
        "    for i in range(len(boxes_list)):\n",
        "        box = boxes_list[i]\n",
        "        if box[0] != new_box[0]:\n",
        "            continue\n",
        "        iou = bb_intersection_over_union(box[2:], new_box[2:])\n",
        "        if iou > best_iou:\n",
        "            best_index = i\n",
        "            best_iou = iou\n",
        "\n",
        "    return best_index, best_iou\n",
        "\n",
        "\n",
        "def weighted_boxes_fusion(boxes_list, scores_list, labels_list, weights=None, iou_thr=0.55, skip_box_thr=0.0, conf_type='avg', allows_overflow=False):\n",
        "    '''\n",
        "    :param boxes_list: list of boxes predictions from each model, each box is 4 numbers.\n",
        "    It has 3 dimensions (models_number, model_preds, 4)\n",
        "    Order of boxes: x1, y1, x2, y2. We expect float normalized coordinates\n",
        "    :param scores_list: list of scores for each model\n",
        "    :param labels_list: list of labels for each model\n",
        "    :param weights: list of weights for each model. Default: None, which means weight == 1 for each model\n",
        "    :param iou_thr: IoU value for boxes to be a match\n",
        "    :param skip_box_thr: exclude boxes with score lower than this variable\n",
        "    :param conf_type: how to calculate confidence in weighted boxes. 'avg': average value, 'max': maximum value\n",
        "    :param allows_overflow: false if we want confidence score not exceed 1.0\n",
        "    :return: boxes: boxes coordinates (Order of boxes: x1, y1, x2, y2).\n",
        "    :return: scores: confidence scores\n",
        "    :return: labels: boxes labels\n",
        "    '''\n",
        "\n",
        "    if weights is None:\n",
        "        weights = np.ones(len(boxes_list))\n",
        "    if len(weights) != len(boxes_list):\n",
        "        print('Warning: incorrect number of weights {}. Must be: {}. Set weights equal to 1.'.format(len(weights), len(boxes_list)))\n",
        "        weights = np.ones(len(boxes_list))\n",
        "    weights = np.array(weights)\n",
        "\n",
        "    if conf_type not in ['avg', 'max']:\n",
        "        print('Unknown conf_type: {}. Must be \"avg\" or \"max\"'.format(conf_type))\n",
        "        exit()\n",
        "\n",
        "    filtered_boxes = prefilter_boxes(boxes_list, scores_list, labels_list, weights, skip_box_thr)\n",
        "    if len(filtered_boxes) == 0:\n",
        "        return np.zeros((0, 4)), np.zeros((0,)), np.zeros((0,))\n",
        "\n",
        "    overall_boxes = []\n",
        "    for label in filtered_boxes:\n",
        "        boxes = filtered_boxes[label]\n",
        "        new_boxes = []\n",
        "        weighted_boxes = []\n",
        "\n",
        "        # Clusterize boxes\n",
        "        for j in range(0, len(boxes)):\n",
        "            index, best_iou = find_matching_box(weighted_boxes, boxes[j], iou_thr)\n",
        "            if index != -1:\n",
        "                new_boxes[index].append(boxes[j])\n",
        "                weighted_boxes[index] = get_weighted_box(new_boxes[index], conf_type)\n",
        "            else:\n",
        "                new_boxes.append([boxes[j].copy()])\n",
        "                weighted_boxes.append(boxes[j].copy())\n",
        "\n",
        "        # Rescale confidence based on number of models and boxes\n",
        "        for i in range(len(new_boxes)):\n",
        "            if not allows_overflow:\n",
        "                weighted_boxes[i][1] = weighted_boxes[i][1] * min(weights.sum(), len(new_boxes[i])) / weights.sum()\n",
        "            else:\n",
        "                weighted_boxes[i][1] = weighted_boxes[i][1] * len(new_boxes[i]) / weights.sum()\n",
        "        overall_boxes.append(np.array(weighted_boxes))\n",
        "\n",
        "    overall_boxes = np.concatenate(overall_boxes, axis=0)\n",
        "    overall_boxes = overall_boxes[overall_boxes[:, 1].argsort()[::-1]]\n",
        "    boxes = overall_boxes[:, 2:]\n",
        "    scores = overall_boxes[:, 1]\n",
        "    labels = overall_boxes[:, 0]\n",
        "    return boxes, scores, labels"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPDzN9WpzLWk"
      },
      "source": [
        "# fusion validation results\n",
        "new_results = []\n",
        "for image_index in range(len(dict_predictions[model_name])):\n",
        "  print(image_index)\n",
        "  unique_image_ids = np.unique([dict_predictions[model_name][image_index][\"image_id\"] for model_name in dict_models.keys()])\n",
        "  assert len(unique_image_ids) == 1\n",
        "  image_id = unique_image_ids[0]\n",
        "  im = cv2.imread(\"./val2017/{0:012}.jpg\".format(image_id))\n",
        "  img_h, img_w = im.shape[:2]\n",
        "  boxes_list, scores_list, labels_list = [], [], []\n",
        "  for model_name in dict_models.keys():\n",
        "    instances = dict_predictions[model_name][image_index][\"instances\"]\n",
        "    boxes = []\n",
        "    for instance in instances: # (x0, y0, w, h) -> (x0, y0, x1, y1)\n",
        "      x0,y0,w,h = instance[\"bbox\"]\n",
        "      boxes.append([x0/img_w, y0/img_h, (x0+w)/img_w, (y0+h)/img_h])\n",
        "    scores = [instance[\"score\"] for instance in instances]\n",
        "    labels = [instance[\"category_id\"] for instance in instances]\n",
        "    boxes_list.append(boxes)\n",
        "    scores_list.append(scores)\n",
        "    labels_list.append(labels)\n",
        "    \n",
        "    # from detectron2.structures.instances import Instances\n",
        "    # im = cv2.imread(\"./val2017/000000000139.jpg\")\n",
        "    # dict_for_plot = Instances(im.shape[:2], pred_boxes=boxes, pred_classes=labels, scores=scores)\n",
        "    # v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(dict_cfg[\"r101_c4\"].DATASETS.TEST[0]), scale=1.2)\n",
        "    # out = v.draw_instance_predictions(dict_for_plot)\n",
        "    # cv2_imshow(out.get_image()[:, :, ::-1])\n",
        "\n",
        "  boxes_wbf, scores, labels = weighted_boxes_fusion(boxes_list, scores_list, labels_list)\n",
        "  boxes = []\n",
        "  for box in boxes_wbf: # (x0, y0, x1, y1) -> (x0, y0, w, h)\n",
        "    x0, y0, x1, y1 = box \n",
        "    boxes.append([x0*img_w, y0*img_h, (x1-x0)*img_w, (y1-y0)*img_h])\n",
        "  instances = []\n",
        "  for instance_index in range(len(boxes)):\n",
        "    bbox = boxes[instance_index]\n",
        "    category_id = labels[instance_index]\n",
        "    label = labels[instance_index]\n",
        "    score = scores[instance_index]\n",
        "    instances.append({'image_id': image_id, 'category_id':category_id, 'bbox':bbox, 'score':score, 'segmentation':[[]], 'area':bbox[-2]*bbox[-1], 'id':instance_index+1})\n",
        "  new_results.append({\"image_id\":image_id, \"instances\":instances})\n",
        "\n",
        "  # from detectron2.structures.instances import Instances\n",
        "  # im = cv2.imread(\"./val2017/000000000139.jpg\")\n",
        "  # dict_for_plot = Instances(im.shape[:2], pred_boxes=[instance[\"bbox\"] for instance in instances], pred_classes=[instance[\"category_id\"] for instance in instances], scores=[instance[\"score\"] for instance in instances])\n",
        "  # v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(dict_cfg[\"r101_c4\"].DATASETS.TEST[0]), scale=1.2)\n",
        "  # out = v.draw_instance_predictions(dict_for_plot)\n",
        "  # cv2_imshow(out.get_image()[:, :, ::-1])\n",
        "  \n",
        "# save to file\n",
        "from detectron2.utils.file_io import PathManager\n",
        "file_path = os.path.join(\"ensemble_instances_predictions.pth\")\n",
        "with PathManager.open(file_path, \"wb\") as f:\n",
        "    torch.save(new_results, f)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKpzmhA-MAkK"
      },
      "source": [
        "!cp ensemble_instances_predictions.pth gdrive/MyDrive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THgoO9e06X_Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c7b5785-0d1d-4ef4-f34d-c6861a4ec7bd"
      },
      "source": [
        "# measure individual model's performance\n",
        "for dataset in [\"val2017\"]:\n",
        "  for model_name, model in dict_models.items():\n",
        "    evaluator = COCOEvaluator(dataset, dict_cfg[model_name], False)\n",
        "    predictions = torch.load(\"ensemble_instances_predictions.pth\")\n",
        "    evaluator._predictions = predictions\n",
        "    evaluator.evaluate()"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/24 11:45:33 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly\n",
            "\u001b[32m[01/24 11:45:39 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[01/24 11:45:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.31s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "COCOeval_opt.evaluate() finished in 9.08 seconds.\n",
            "Accumulating evaluation results...\n",
            "COCOeval_opt.accumulate() finished in 1.29 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.459\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.665\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.502\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.294\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.495\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.589\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.362\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.575\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.607\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.430\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.643\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.748\n",
            "\u001b[32m[01/24 11:45:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 45.871 | 66.524 | 50.215 | 29.365 | 49.518 | 58.857 |\n",
            "\u001b[32m[01/24 11:45:50 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category     | AP     | category       | AP     |\n",
            "|:--------------|:-------|:-------------|:-------|:---------------|:-------|\n",
            "| person        | 58.869 | bicycle      | 36.553 | car            | 48.080 |\n",
            "| motorcycle    | 47.956 | airplane     | 69.524 | bus            | 70.059 |\n",
            "| train         | 66.488 | truck        | 39.967 | boat           | 31.918 |\n",
            "| traffic light | 30.296 | fire hydrant | 73.224 | stop sign      | 70.244 |\n",
            "| parking meter | 50.170 | bench        | 28.692 | bird           | 40.934 |\n",
            "| cat           | 72.023 | dog          | 65.173 | horse          | 62.327 |\n",
            "| sheep         | 56.288 | cow          | 60.066 | elephant       | 65.843 |\n",
            "| bear          | 74.218 | zebra        | 69.953 | giraffe        | 71.103 |\n",
            "| backpack      | 19.872 | umbrella     | 44.040 | handbag        | 19.039 |\n",
            "| tie           | 39.446 | suitcase     | 45.260 | frisbee        | 67.747 |\n",
            "| skis          | 28.438 | snowboard    | 41.774 | sports ball    | 49.276 |\n",
            "| kite          | 46.983 | baseball bat | 33.051 | baseball glove | 41.587 |\n",
            "| skateboard    | 56.849 | surfboard    | 43.146 | tennis racket  | 54.249 |\n",
            "| bottle        | 43.316 | wine glass   | 40.919 | cup            | 47.574 |\n",
            "| fork          | 44.444 | knife        | 24.244 | spoon          | 23.451 |\n",
            "| bowl          | 46.719 | banana       | 26.367 | apple          | 25.406 |\n",
            "| sandwich      | 37.829 | orange       | 34.433 | broccoli       | 26.484 |\n",
            "| carrot        | 25.723 | hot dog      | 37.255 | pizza          | 55.962 |\n",
            "| donut         | 50.913 | cake         | 40.785 | chair          | 32.101 |\n",
            "| couch         | 46.581 | potted plant | 31.525 | bed            | 43.118 |\n",
            "| dining table  | 32.053 | toilet       | 63.568 | tv             | 60.936 |\n",
            "| laptop        | 65.916 | mouse        | 65.357 | remote         | 36.348 |\n",
            "| keyboard      | 54.798 | cell phone   | 40.248 | microwave      | 61.116 |\n",
            "| oven          | 36.176 | toaster      | 44.973 | sink           | 40.398 |\n",
            "| refrigerator  | 59.015 | book         | 18.398 | clock          | 52.731 |\n",
            "| vase          | 41.389 | scissors     | 30.737 | teddy bear     | 50.194 |\n",
            "| hair drier    | 10.171 | toothbrush   | 29.256 |                |        |\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/24 11:45:51 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly\n",
            "\u001b[32m[01/24 11:45:58 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[01/24 11:45:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.31s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "COCOeval_opt.evaluate() finished in 10.99 seconds.\n",
            "Accumulating evaluation results...\n",
            "COCOeval_opt.accumulate() finished in 1.32 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.459\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.665\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.502\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.294\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.495\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.589\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.362\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.575\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.607\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.430\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.643\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.748\n",
            "\u001b[32m[01/24 11:46:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 45.871 | 66.524 | 50.215 | 29.365 | 49.518 | 58.857 |\n",
            "\u001b[32m[01/24 11:46:11 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category     | AP     | category       | AP     |\n",
            "|:--------------|:-------|:-------------|:-------|:---------------|:-------|\n",
            "| person        | 58.869 | bicycle      | 36.553 | car            | 48.080 |\n",
            "| motorcycle    | 47.956 | airplane     | 69.524 | bus            | 70.059 |\n",
            "| train         | 66.488 | truck        | 39.967 | boat           | 31.918 |\n",
            "| traffic light | 30.296 | fire hydrant | 73.224 | stop sign      | 70.244 |\n",
            "| parking meter | 50.170 | bench        | 28.692 | bird           | 40.934 |\n",
            "| cat           | 72.023 | dog          | 65.173 | horse          | 62.327 |\n",
            "| sheep         | 56.288 | cow          | 60.066 | elephant       | 65.843 |\n",
            "| bear          | 74.218 | zebra        | 69.953 | giraffe        | 71.103 |\n",
            "| backpack      | 19.872 | umbrella     | 44.040 | handbag        | 19.039 |\n",
            "| tie           | 39.446 | suitcase     | 45.260 | frisbee        | 67.747 |\n",
            "| skis          | 28.438 | snowboard    | 41.774 | sports ball    | 49.276 |\n",
            "| kite          | 46.983 | baseball bat | 33.051 | baseball glove | 41.587 |\n",
            "| skateboard    | 56.849 | surfboard    | 43.146 | tennis racket  | 54.249 |\n",
            "| bottle        | 43.316 | wine glass   | 40.919 | cup            | 47.574 |\n",
            "| fork          | 44.444 | knife        | 24.244 | spoon          | 23.451 |\n",
            "| bowl          | 46.719 | banana       | 26.367 | apple          | 25.406 |\n",
            "| sandwich      | 37.829 | orange       | 34.433 | broccoli       | 26.484 |\n",
            "| carrot        | 25.723 | hot dog      | 37.255 | pizza          | 55.962 |\n",
            "| donut         | 50.913 | cake         | 40.785 | chair          | 32.101 |\n",
            "| couch         | 46.581 | potted plant | 31.525 | bed            | 43.118 |\n",
            "| dining table  | 32.053 | toilet       | 63.568 | tv             | 60.936 |\n",
            "| laptop        | 65.916 | mouse        | 65.357 | remote         | 36.348 |\n",
            "| keyboard      | 54.798 | cell phone   | 40.248 | microwave      | 61.116 |\n",
            "| oven          | 36.176 | toaster      | 44.973 | sink           | 40.398 |\n",
            "| refrigerator  | 59.015 | book         | 18.398 | clock          | 52.731 |\n",
            "| vase          | 41.389 | scissors     | 30.737 | teddy bear     | 50.194 |\n",
            "| hair drier    | 10.171 | toothbrush   | 29.256 |                |        |\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/24 11:46:12 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass tasks in directly\n",
            "\u001b[32m[01/24 11:46:19 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[01/24 11:46:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.31s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "COCOeval_opt.evaluate() finished in 9.52 seconds.\n",
            "Accumulating evaluation results...\n",
            "COCOeval_opt.accumulate() finished in 1.29 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.459\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.665\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.502\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.294\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.495\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.589\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.362\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.575\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.607\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.430\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.643\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.748\n",
            "\u001b[32m[01/24 11:46:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 45.871 | 66.524 | 50.215 | 29.365 | 49.518 | 58.857 |\n",
            "\u001b[32m[01/24 11:46:31 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category     | AP     | category       | AP     |\n",
            "|:--------------|:-------|:-------------|:-------|:---------------|:-------|\n",
            "| person        | 58.869 | bicycle      | 36.553 | car            | 48.080 |\n",
            "| motorcycle    | 47.956 | airplane     | 69.524 | bus            | 70.059 |\n",
            "| train         | 66.488 | truck        | 39.967 | boat           | 31.918 |\n",
            "| traffic light | 30.296 | fire hydrant | 73.224 | stop sign      | 70.244 |\n",
            "| parking meter | 50.170 | bench        | 28.692 | bird           | 40.934 |\n",
            "| cat           | 72.023 | dog          | 65.173 | horse          | 62.327 |\n",
            "| sheep         | 56.288 | cow          | 60.066 | elephant       | 65.843 |\n",
            "| bear          | 74.218 | zebra        | 69.953 | giraffe        | 71.103 |\n",
            "| backpack      | 19.872 | umbrella     | 44.040 | handbag        | 19.039 |\n",
            "| tie           | 39.446 | suitcase     | 45.260 | frisbee        | 67.747 |\n",
            "| skis          | 28.438 | snowboard    | 41.774 | sports ball    | 49.276 |\n",
            "| kite          | 46.983 | baseball bat | 33.051 | baseball glove | 41.587 |\n",
            "| skateboard    | 56.849 | surfboard    | 43.146 | tennis racket  | 54.249 |\n",
            "| bottle        | 43.316 | wine glass   | 40.919 | cup            | 47.574 |\n",
            "| fork          | 44.444 | knife        | 24.244 | spoon          | 23.451 |\n",
            "| bowl          | 46.719 | banana       | 26.367 | apple          | 25.406 |\n",
            "| sandwich      | 37.829 | orange       | 34.433 | broccoli       | 26.484 |\n",
            "| carrot        | 25.723 | hot dog      | 37.255 | pizza          | 55.962 |\n",
            "| donut         | 50.913 | cake         | 40.785 | chair          | 32.101 |\n",
            "| couch         | 46.581 | potted plant | 31.525 | bed            | 43.118 |\n",
            "| dining table  | 32.053 | toilet       | 63.568 | tv             | 60.936 |\n",
            "| laptop        | 65.916 | mouse        | 65.357 | remote         | 36.348 |\n",
            "| keyboard      | 54.798 | cell phone   | 40.248 | microwave      | 61.116 |\n",
            "| oven          | 36.176 | toaster      | 44.973 | sink           | 40.398 |\n",
            "| refrigerator  | 59.015 | book         | 18.398 | clock          | 52.731 |\n",
            "| vase          | 41.389 | scissors     | 30.737 | teddy bear     | 50.194 |\n",
            "| hair drier    | 10.171 | toothbrush   | 29.256 |                |        |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwrA-LXFMHOU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}